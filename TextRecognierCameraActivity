package com.spark121;

import android.app.Activity;
import android.content.Context;
import android.content.Intent;
import android.graphics.Bitmap;
import android.graphics.BitmapFactory;
import android.graphics.Matrix;
import android.graphics.Point;
import android.graphics.Rect;
import android.graphics.drawable.BitmapDrawable;
import android.hardware.camera2.CameraAccessException;
import android.hardware.camera2.CameraCharacteristics;
import android.hardware.camera2.CameraManager;
import android.hardware.camera2.CameraMetadata;
import android.media.ExifInterface;
import android.net.Uri;
import android.os.Build;
import android.os.Bundle;
import android.os.Environment;
import android.provider.MediaStore;
import android.support.annotation.NonNull;
import android.support.annotation.RequiresApi;
import android.support.v4.content.FileProvider;
import android.support.v4.graphics.BitmapCompat;
import android.util.Log;
import android.util.SparseIntArray;
import android.view.Surface;
import android.view.View;
import android.view.Window;
import android.widget.Button;
import android.widget.ImageView;
import android.widget.TextView;
import android.widget.Toast;

import com.google.android.gms.tasks.OnFailureListener;
import com.google.android.gms.tasks.OnSuccessListener;
import com.google.android.gms.tasks.Task;
import com.google.firebase.ml.vision.FirebaseVision;
import com.google.firebase.ml.vision.common.FirebaseVisionImage;
import com.google.firebase.ml.vision.common.FirebaseVisionImageMetadata;
import com.google.firebase.ml.vision.text.FirebaseVisionText;
import com.google.firebase.ml.vision.text.FirebaseVisionTextRecognizer;
import com.google.firebase.ml.vision.text.RecognizedLanguage;
import com.spark121.dto.TextModel;

import java.io.ByteArrayOutputStream;
import java.io.File;
import java.io.IOException;
import java.nio.ByteBuffer;
import java.util.Hashtable;
import java.util.List;
import java.util.TreeMap;
import java.util.Vector;

public class TextRecognierCamera extends Activity {

    private static final String TAG = "TextRecognierCamera";
    public final String APP_TAG = "TextRecognierCamera";
    public final static int CAPTURE_IMAGE_ACTIVITY_REQUEST_CODE = 1034;
    public String photoFileName = "photo.jpg";
    File photoFile;

    ImageView ivPreview;
    TextView textView;

    @Override
    protected void onCreate(Bundle savedInstanceState) {
        super.onCreate(savedInstanceState);
        requestWindowFeature(Window.FEATURE_NO_TITLE);
        setContentView(R.layout.text_recognier_camera);


         textView = findViewById(R.id.text);
         ivPreview = (ImageView) findViewById(R.id.capturedImage);

        ImageView backbutton = (ImageView) findViewById(R.id.bcbutton);
        backbutton.setOnClickListener(new View.OnClickListener() {
            public void onClick(View v) {
                finish();
            }
        });

        onLaunchCamera();
    }

    Uri fileProvider;


    public void onLaunchCamera() {
        // create Intent to take a picture and return control to the calling application
        Intent intent = new Intent(MediaStore.ACTION_IMAGE_CAPTURE);
        // Create a File reference to access to future access
        photoFile = getPhotoFileUri(photoFileName);

        // wrap File object into a content provider
        // required for API >= 24
        // See https://guides.codepath.com/android/Sharing-Content-with-Intents#sharing-files-with-api-24-or-higher
         fileProvider = FileProvider.getUriForFile(TextRecognierCamera.this, "com.codepath.fileprovider", photoFile);
        intent.putExtra(MediaStore.EXTRA_OUTPUT, fileProvider);

        // If you call startActivityForResult() using an intent that no app can handle, your app will crash.
        // So as long as the result is not null, it's safe to use the intent.
        if (intent.resolveActivity(getPackageManager()) != null) {
            // Start the image capture intent to take photo
            startActivityForResult(intent, CAPTURE_IMAGE_ACTIVITY_REQUEST_CODE);
        }
    }


    // Returns the File for a photo stored on disk given the fileName
    public File getPhotoFileUri(String fileName) {
        // Get safe storage directory for photos
        // Use `getExternalFilesDir` on Context to access package-specific directories.
        // This way, we don't need to request external read/write runtime permissions.
        File mediaStorageDir = new File(getExternalFilesDir(Environment.DIRECTORY_PICTURES), APP_TAG);

        // Create the storage directory if it does not exist
        if (!mediaStorageDir.exists() && !mediaStorageDir.mkdirs()){
            Log.d(APP_TAG, "failed to create directory");
        }

        // Return the file target for the photo based on filename
        File file = new File(mediaStorageDir.getPath() + File.separator + fileName);

        return file;
    }


    @androidx.annotation.RequiresApi(api = Build.VERSION_CODES.LOLLIPOP)
    @Override
    public void onActivityResult(int requestCode, int resultCode, Intent data) {
        if (requestCode == CAPTURE_IMAGE_ACTIVITY_REQUEST_CODE) {
            if (resultCode == RESULT_OK) {
                // by this point we have the camera photo on disk
                Bitmap takenImage = BitmapFactory.decodeFile(photoFile.getAbsolutePath());
                // RESIZE BITMAP, see section below
                // Load the taken image into a preview

                Bitmap rotatedBitmap =  getRotatedImage(photoFile.getAbsolutePath(),takenImage);

                ivPreview.setVisibility(View.VISIBLE);
                textView.setVisibility(View.GONE);

                ivPreview.setImageBitmap(takenImage);


                int bytes = takenImage.getByteCount();

                ByteBuffer buffer = ByteBuffer.allocate(bytes); //Create a new buffer
                takenImage.copyPixelsToBuffer(buffer);


                String backCameraId = null;
                CameraManager manager = (CameraManager) getSystemService(Context.CAMERA_SERVICE);
                try {
                    for(String cameraId:manager.getCameraIdList()){
                        CameraCharacteristics cameraCharacteristics = manager.getCameraCharacteristics(cameraId);
                        Integer facing = cameraCharacteristics.get(CameraCharacteristics.LENS_FACING);
                        if(facing== CameraMetadata.LENS_FACING_BACK) {
                            backCameraId = cameraId;
                            break;
                        }
                    }
                } catch (CameraAccessException e) {
                    e.printStackTrace();
                }
                Log.d(TAG, "back camera exists ? "+(backCameraId!=null));
                Log.d(TAG, "back camera id  :"+backCameraId);


                int rotation = 0;


                try {
                    rotation= getRotationCompensation(backCameraId,TextRecognierCamera.this,this);
                } catch (CameraAccessException e) {
                    e.printStackTrace();
                }

                Bitmap bitmap = (((BitmapDrawable)ivPreview.getDrawable().getCurrent()).getBitmap());

                imageFromPath(this,fileProvider);

                /*ByteArrayOutputStream stream = new ByteArrayOutputStream();
                takenImage.compress(Bitmap.CompressFormat.PNG, 100, stream);
                byte[] byteArray = stream.toByteArray();
                imageFromArray(byteArray,rotation);*/

              //ByteBuffer byteBuffer = ByteBuffer.allocateDirect(BitmapCompat.getAllocationByteCount(bitmap));
               /* ByteBuffer buffer1 = ByteBuffer.allocate(bitmap.getByteCount());
                bitmap.copyPixelsToBuffer(buffer1);
                 imageFromBuffer(buffer1,rotation);*/

              //  runTextRecognition();

            } else { // Result was a failure
                Toast.makeText(this, "Picture wasn't taken!", Toast.LENGTH_SHORT).show();
            }
        }
    }

    private void imageFromPath(Context context, Uri uri) {
        // [START image_from_path]
        FirebaseVisionImage image = null;
        try {
            image = FirebaseVisionImage.fromFilePath(context, uri);
        } catch (IOException e) {
            e.printStackTrace();
        }
        // [START get_detector_default]
        FirebaseVisionTextRecognizer detector = FirebaseVision.getInstance().getOnDeviceTextRecognizer();

        Task<FirebaseVisionText> result =
                detector.processImage(image)
                        .addOnSuccessListener(new OnSuccessListener<FirebaseVisionText>() {
                            @Override
                            public void onSuccess(FirebaseVisionText texts) {

                                System.out.println();
                                processTextBlock(texts);
                              //  getText1(texts);

                            }
                        })
                        .addOnFailureListener(
                                new OnFailureListener() {
                                    @Override
                                    public void onFailure(@NonNull Exception e) {
                                        e.printStackTrace();
                                        System.out.println();
                                    }
                                });
    }





    // [START get_rotation]
    private static final SparseIntArray ORIENTATIONS = new SparseIntArray();
    static {
        ORIENTATIONS.append(Surface.ROTATION_0, 90);
        ORIENTATIONS.append(Surface.ROTATION_90, 0);
        ORIENTATIONS.append(Surface.ROTATION_180, 270);
        ORIENTATIONS.append(Surface.ROTATION_270, 180);
    }

    /**
     * Get the angle by which an image must be rotated given the device's current
     * orientation.
     */
    @RequiresApi(api = Build.VERSION_CODES.LOLLIPOP)
    private int getRotationCompensation(String cameraId, Activity activity, Context context)
            throws CameraAccessException {

        int deviceRotation = activity.getWindowManager().getDefaultDisplay().getRotation();
        int rotationCompensation = ORIENTATIONS.get(deviceRotation);

        CameraManager cameraManager = (CameraManager) context.getSystemService(CAMERA_SERVICE);
        int sensorOrientation = cameraManager.getCameraCharacteristics(cameraId).get(CameraCharacteristics.SENSOR_ORIENTATION);
        rotationCompensation = (rotationCompensation + sensorOrientation + 270) % 360;

        int result;
        switch (rotationCompensation) {
            case 0:
                result = FirebaseVisionImageMetadata.ROTATION_0;
                break;
            case 90:
                result = FirebaseVisionImageMetadata.ROTATION_90;
                break;
            case 180:
                result = FirebaseVisionImageMetadata.ROTATION_180;
                break;
            case 270:
                result = FirebaseVisionImageMetadata.ROTATION_270;
                break;
            default:
                result = FirebaseVisionImageMetadata.ROTATION_0;
                Log.e(TAG, "Bad rotation value: " + rotationCompensation);
        }
        return result;
    }
    // [END get_rotation]

    @RequiresApi(api = Build.VERSION_CODES.LOLLIPOP)
    private void getCompensation(Activity activity, Context context) throws CameraAccessException {

        // Get the ID of the camera using CameraManager. Then:

        String backCameraId = null;
        CameraManager manager = (CameraManager) context.getSystemService(Context.CAMERA_SERVICE);
        for(String cameraId:manager.getCameraIdList()){
            CameraCharacteristics cameraCharacteristics = manager.getCameraCharacteristics(cameraId);
            Integer facing = cameraCharacteristics.get(CameraCharacteristics.LENS_FACING);
            if(facing== CameraMetadata.LENS_FACING_BACK) {
                backCameraId = cameraId;
                break;
            }
        }
        Log.d(TAG, "back camera exists ? "+(backCameraId!=null));
        Log.d(TAG, "back camera id  :"+backCameraId);



        int rotation = getRotationCompensation(backCameraId, activity, context);
    }





    private void runTextRecognition() {

        FirebaseVisionImage image = FirebaseVisionImage.fromBitmap(((BitmapDrawable)ivPreview.getDrawable().getCurrent()).getBitmap());

        FirebaseVisionTextRecognizer detector = FirebaseVision.getInstance().getOnDeviceTextRecognizer();

        detector.processImage(image)
                .addOnSuccessListener(
                        new OnSuccessListener<FirebaseVisionText>() {
                            @Override
                            public void onSuccess(FirebaseVisionText texts) {
                                //      processTextRecognitionResult(texts);
                                processTextBlock(texts);
                                getText1(texts);

                                System.out.println();
                            }
                        })
                .addOnFailureListener(
                        new OnFailureListener() {
                            @Override
                            public void onFailure(@NonNull Exception e) {
                                e.printStackTrace();
                            }
                        });
    }



    public void getText1(FirebaseVisionText result){


        String resultText = result.getText();
        System.out.println();


        textView.setText(resultText);

        ivPreview.setVisibility(View.GONE);
        textView.setVisibility(View.VISIBLE);



        String text = null;

        for(Vector vector: tm.values()){

            for(int i=0; i<vector.size(); i++){

                TextModel textModel = (TextModel) vector.get(i);

                text = text + text +"/n";
            }

        }

        System.out.println();

    }


    Hashtable<Integer, Vector> hashtable = new Hashtable<>();

    TreeMap<Integer, Vector> tm= new TreeMap<Integer, Vector>();


    private void processTextBlock(FirebaseVisionText result) {
        // [START mlkit_process_text_block]
        String resultText = result.getText();
        for (FirebaseVisionText.TextBlock block: result.getTextBlocks()) {
            String blockText = block.getText();
            Float blockConfidence = block.getConfidence();
            List<RecognizedLanguage> blockLanguages = block.getRecognizedLanguages();
            Point[] blockCornerPoints = block.getCornerPoints();
            Rect blockFrame = block.getBoundingBox();
            for (FirebaseVisionText.Line line: block.getLines()) {
                String lineText = line.getText();
                Float lineConfidence = line.getConfidence();
                List<RecognizedLanguage> lineLanguages = line.getRecognizedLanguages();
                Point[] lineCornerPoints = line.getCornerPoints();
                Rect lineFrame = line.getBoundingBox();

                TextModel textModel = new TextModel();

                Vector <TextModel>vector = new Vector();

                textModel.text = line.getText();
                textModel.x =  lineFrame.left;
                textModel.y = lineFrame.top;

                /*textModel.x = lineFrame.centerX();
                textModel.y = lineFrame.centerY();*/

                textModel.height = lineFrame.height();
                textModel.width = lineFrame.width();

                vector.add(textModel);

                hashtable.put(textModel.y,vector);
                tm.put(textModel.y,vector);


                Log.e("","");

                for (FirebaseVisionText.Element element: line.getElements()) {
                    String elementText = element.getText();
                    Float elementConfidence = element.getConfidence();
                    List<RecognizedLanguage> elementLanguages = element.getRecognizedLanguages();
                    Point[] elementCornerPoints = element.getCornerPoints();
                    Rect elementFrame = element.getBoundingBox();
                }
            }
        }

        Log.e("","");
        // [END mlkit_process_text_block]
        setText1();
    }


    public void setText1(){

        String text="";

        int y=0;

        for(Vector vector: tm.values()){

            for(int i=0; i<vector.size(); i++){

                TextModel textModel = (TextModel) vector.get(i);

                y = textModel.y;

                if((y - textModel.y) == 20){
                    text = text + " " + textModel.text ;
                }else{
                    text = text + '\n' + textModel.text ;
                }

               // text = text + '\n' + textModel.text ;
            }

        }

        System.out.println();

        textView.setText(text);

        ivPreview.setVisibility(View.GONE);
        textView.setVisibility(View.VISIBLE);

    }



    public Bitmap getRotatedImage(String photoPath,Bitmap bitmap){

        ExifInterface ei = null;
        try {
            ei = new ExifInterface(photoPath);
        } catch (IOException e) {
            e.printStackTrace();
        }
        int orientation = ei.getAttributeInt(ExifInterface.TAG_ORIENTATION,
                ExifInterface.ORIENTATION_UNDEFINED);

        Bitmap rotatedBitmap = null;
        switch(orientation) {

            case ExifInterface.ORIENTATION_ROTATE_90:
                rotatedBitmap = rotateImage(bitmap, 90);
                break;

            case ExifInterface.ORIENTATION_ROTATE_180:
                rotatedBitmap = rotateImage(bitmap, 180);
                break;

            case ExifInterface.ORIENTATION_ROTATE_270:
                rotatedBitmap = rotateImage(bitmap, 270);
                break;

            case ExifInterface.ORIENTATION_NORMAL:
            default:
                rotatedBitmap = bitmap;
        }

        return rotatedBitmap;
    }


    public static Bitmap rotateImage(Bitmap source, float angle) {
        Matrix matrix = new Matrix();
        matrix.postRotate(angle);
        return Bitmap.createBitmap(source, 0, 0, source.getWidth(), source.getHeight(), matrix, true);
    }
}
